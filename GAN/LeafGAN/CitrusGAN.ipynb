{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "leaf datasets are from tensorflow datasets and maybe swedish leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython\n",
    "import sys\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import PIL.Image\n",
    "from PIL import ImageOps\n",
    "import PIL\n",
    "import datetime\n",
    "import tensorboard\n",
    "import sklearn\n",
    "import subprocess\n",
    "import pandas\n",
    "import time\n",
    "import glob\n",
    "from IPython import display\n",
    "from apiclient import discovery\n",
    "import httplib2\n",
    "import requests\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from google.colab import drive             \n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset loading\n",
    "\n",
    "data_path = pathlib.Path('/content/drive/MyDrive/CitrusDataset/')\n",
    "\n",
    "# data_path_test = pathlib.Path('/content/drive/MyDrive/CarsDataset')\n",
    "\n",
    "\n",
    "dataset_path = tf.keras.utils.image_dataset_from_directory(        # Training dataset\n",
    "    data_path,\n",
    "    labels= 'inferred',\n",
    "    label_mode= None,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed= 1,\n",
    "    batch_size=8,\n",
    "    image_size=(128, 128),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=True)\n",
    "\n",
    "dataset_path_val = tf.keras.utils.image_dataset_from_directory(      #Validation dataset\n",
    "    data_path,\n",
    "    labels= 'inferred',\n",
    "    label_mode= None,\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed= 2,\n",
    "    batch_size=8,\n",
    "    image_size=(128, 128),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=True)\n",
    "\n",
    "\n",
    "# BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 500\n",
    "noise_dim = 128\n",
    "num_examples_to_generate = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE=tf.data.AUTOTUNE\n",
    "dataset_path = dataset_path.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "dataset_path_val = dataset_path_val.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The generator\n",
    "\n",
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential([\n",
    "    # tf.keras.layers.Reshape((5, 28, 28, 1)),\n",
    "    # tf.keras.layers.Rescaling(scale=1 / 127.5, offset=-1), \n",
    "    # tf.keras.layers.Normalization(axis=None, mean=0, variance=1),\n",
    "    tf.keras.layers.Dense(32*32*512, use_bias=False, input_shape=(128,)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "\n",
    "    tf.keras.layers.Reshape((32, 32, 512)),\n",
    "    # assert model.output_shape == (None, 7, 7, 256)  # Note: None is the batch size\n",
    "\n",
    "    tf.keras.layers.Conv2DTranspose(512, (5, 5), strides=(1, 1), padding='same', use_bias=False, kernel_initializer='glorot_normal'),\n",
    "    # assert model.output_shape == (None, 7, 7, 128)\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "\n",
    "    # tf.keras.layers.Conv2DTranspose(256, (5, 5), strides=(1, 1), padding='same', use_bias=False),# kernel_initializer='glorot_normal'),\n",
    "    # # assert model.output_shape == (None, 7, 7, 128)\n",
    "    # tf.keras.layers.BatchNormalization(),\n",
    "    # tf.keras.layers.LeakyReLU(),\n",
    "\n",
    "    tf.keras.layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False, kernel_initializer='glorot_normal'),\n",
    "    # assert model.output_shape == (None, 7, 7, 128)\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "\n",
    "    tf.keras.layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False, kernel_initializer='glorot_normal'),\n",
    "    # assert model.output_shape == (None, 14, 14, 64)\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "\n",
    "    tf.keras.layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh', kernel_initializer='glorot_normal'),\n",
    "    # assert model.output_shape == (None, 28, 28, 1)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image generation\n",
    "\n",
    "generator = make_generator_model()    \n",
    "noise = tf.random.normal([1, 128])\n",
    "generated_image = generator(noise, training=True)\n",
    "plt.imshow(generated_image[0, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The discriminator\n",
    "# here some from tensorflow and/or pytorch tutorials others from https://machinelearningmastery.com/practical-guide-to-gan-failure-modes/\n",
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential([\n",
    "    # tf.keras.layers.Normalization(axis=None, mean=0, variance=1),\n",
    "    tf.keras.layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',input_shape=[128, 128, 3], kernel_initializer='glorot_normal'),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "    # tf.keras.layers.Conv2D(512, (5, 5), strides=(2, 2), padding='same', kernel_initializer='glorot_normal'),\n",
    "    # tf.keras.layers.LeakyReLU(),\n",
    "    # tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same', kernel_initializer='glorot_normal'),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(256, (5, 5), strides=(2, 2), padding='same', kernel_initializer='glorot_normal'),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(256, (5, 5), strides=(2, 2), padding='same', kernel_initializer='glorot_normal'),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "    tf.keras.layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same', kernel_initializer='glorot_normal'),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "\n",
    "    # tf.keras.layers.Resizing(128, 128),\n",
    "    # # tf.keras.layers.Rescaling(1./255),\n",
    "    # tf.keras.layers.Conv2D(16, 3, activation='ELU', kernel_regularizer=tf.keras.regularizers.l2(0.001)),  \n",
    "    # tf.keras.layers.MaxPooling2D(),\n",
    "    # tf.keras.layers.Dropout(0.2),                                                                         #DP1\n",
    "    # tf.keras.layers.Conv2D(32, 3, activation='ELU', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    # tf.keras.layers.MaxPooling2D(),\n",
    "    # tf.keras.layers.Dropout(0.2),                                                                         #DP2\n",
    "    # tf.keras.layers.Conv2D(64, 3, activation='ELU', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    # tf.keras.layers.MaxPooling2D(),\n",
    "    # tf.keras.layers.Dropout(0.2),                                                                         #DP3\n",
    "    # tf.keras.layers.Conv2D(128, 3, activation='ELU', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    # tf.keras.layers.MaxPooling2D(),\n",
    "    # tf.keras.layers.Dropout(0.2),  \n",
    "    # tf.keras.layers.Flatten(),\n",
    "    # tf.keras.layers.Dense(128, activation='ELU', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    # tf.keras.layers.Dropout(0.2),                                                                         #DP4\n",
    "    # tf.keras.layers.Dense(128, activation='ELU', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    # tf.keras.layers.Dropout(0.2),                                                                         #DP5\n",
    "    # tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "    \n",
    "    # model.compile(\n",
    "    # optimizer = tf.keras.optimizers.Adam(learning_rate = 0.00008),        # compiling with low learning rate\n",
    "    # loss=tf.losses.BinaryCrossentropy(),\n",
    "    # metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision making\n",
    "\n",
    "discriminator = make_discriminator_model()\n",
    "decision = discriminator(generated_image)\n",
    "print (decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator loss\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(0.0002)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoints\n",
    "\n",
    "checkpoint_dir = '/content/drive/MyDrive/GANCheckpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)\n",
    "manager = tf.train.CheckpointManager(checkpoint, checkpoint_dir , max_to_keep=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      generated_images = generator(noise, training=True)\n",
    "\n",
    "      real_output = discriminator(images, training=True)\n",
    "      fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "      gen_loss = generator_loss(fake_output)\n",
    "      disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    for image_batch in dataset:\n",
    "      train_step(image_batch)\n",
    "\n",
    "  \n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,\n",
    "                             epoch + 1,\n",
    "                             seed)\n",
    "\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "      # manager.save()\n",
    "      print(\"tenth is here\")\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "    # if (epoch + 1) % 11 == 0:\n",
    "    #   service = discovery.build('drive', 'v2')  # stackoverflow stuff\n",
    "    #   service.files().emptyTrash().execute()\n",
    "    # Generate after the final epoch\n",
    "    # display.clear_output(wait=True)\n",
    "    # generate_and_save_images(generator,\n",
    "    #                          epochs,\n",
    "    #                          seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "\n",
    "  predictions = model(test_input, training=True)\n",
    "\n",
    "  # fig = plt.figure(figsize=(1, 1))\n",
    "  for i in range(predictions.shape[0]):\n",
    "      plt.imshow(predictions[i, :, :, 0])\n",
    "      plt.axis('off')\n",
    "  plt.savefig('image_at_epoch_{}.png'.format(epoch))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(generated_image[0])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for restoring\n",
    "# if manager.latest_checkpoint:\n",
    "#   checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "# Train the model\n",
    "train(dataset_path, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A record of changes after getting Leafish shape:\n",
    "\n",
    "- strides on conv2dT2 from (1,1) to (2,2) DOES NOT WORK\n",
    "\n",
    "- the dropout rates of discriminator layers now all 0.2, at 0.1 the leaf disappear\n",
    "\n",
    "- got the generator input shape down from (32,32,512) to (32,32,256) which showed a leafish shape on the first run then vanished in the second. and keep appearing and vanishing with more epochs (big randomness in the results)\n",
    "\n",
    "- now introducing a \"resize\" layer in the start of discriminator to give it (64,64,3) gives good few epochs and then vanish\n",
    "\n",
    "- divide all the discriminator hidden unites numbers by two hope for a longer life for the gradient, and again with the vanishing so will start working on the generator because probably the dis is working by the proof of the first few epochs.\n",
    "\n",
    "- first on the gen got first conv2dT from 512 to 256 A MESS\n",
    "\n",
    "- to get it close from the dis model got 128-128-64-32-3 on gen. EVERYTHING IS GONE i AM NOT DOING GOOD\n",
    "\n",
    "- mul all layer by 2 got some noise in the beginning (I am not good with gens)\n",
    "\n",
    "- just wanted to say that I think something's size is really wrong\n",
    "\n",
    "- now has same conv layer in gen as leafish and training for batch norm is off and first generated image."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
